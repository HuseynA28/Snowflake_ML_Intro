{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "from snowflake.ml._internal.utils import identifier\n",
        "from snowflake.ml.modeling.impute import SimpleImputer\n",
        "from snowflake.ml.modeling.metrics import accuracy_score, precision_score, recall_score\n",
        "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
        "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
        "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
        "from snowflake.ml.registry import model_registry\n",
        "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark import types as T\n",
        "from snowflake.snowpark.functions import col\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session = Session.builder.configs(SnowflakeLoginOptions()).getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df = session.table(\"titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Columns with null values and their respective counts\n",
        "null_counts = [\n",
        "    (col_name, titanic_df.where(col(col_name).isNull()).count())\n",
        "    for col_name in titanic_df.columns\n",
        "]\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df = titanic_df.drop(\n",
        "    [\"AGE\", \"DECK\", \"ALIVE\", \"ADULT_MALE\", \"EMBARKED\", \"SEX\", \"PCLASS\", \"ALONE\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df = titanic_df.withColumn(\"FARE\", titanic_df[\"FARE\"].astype(T.FloatType()))\n",
        "\n",
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_cols = [\"CLASS\", \"WHO\", \"EMBARK_TOWN\"]\n",
        "num_cols = [\"SIBSP\", \"PARCH\", \"FARE\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "impute_cat = SimpleImputer(\n",
        "    input_cols=cat_cols,\n",
        "    output_cols=cat_cols,\n",
        "    strategy=\"most_frequent\",\n",
        "    drop_input_cols=True,\n",
        ")\n",
        "\n",
        "titanic_df = impute_cat.fit(titanic_df).transform(titanic_df)\n",
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OHE = OneHotEncoder(\n",
        "    input_cols=cat_cols,\n",
        "    output_cols=cat_cols,\n",
        "    drop_input_cols=True,\n",
        "    drop=\"first\",\n",
        "    handle_unknown=\"ignore\",\n",
        ")\n",
        "\n",
        "titanic_df = OHE.fit(titanic_df).transform(titanic_df)\n",
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = titanic_df.random_split(weights=[0.8, 0.2], seed=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
        "    \"learning_rate\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    \"max_depth\": list(range(3,6,1)),\n",
        "    \"min_child_weight\": list(range(1,6,1))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session.sql(\n",
        "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=LARGE;\"\n",
        ").collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data scientists may not have the ability to change the warehouse size.  They will usually have access to a larger warehouse and can easily switch as well using session.use_warehouse('bigger_warehouse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(\n",
        "    estimator=XGBClassifier(),\n",
        "    param_grid=parameters,\n",
        "    n_jobs=-1,\n",
        "    scoring=\"accuracy\",\n",
        "    input_cols=train_df.drop(\"SURVIVED\").columns,\n",
        "    label_cols=\"SURVIVED\",\n",
        "    output_cols=\"PRED_SURVIVED\",\n",
        ")\n",
        "\n",
        "# Train\n",
        "grid_search.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session.sql(\n",
        "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=XSMALL;\"\n",
        ").collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = grid_search.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(\n",
        "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print each combination of hyperparameters with their accuracy\n",
        "results = grid_search.to_sklearn().cv_results_\n",
        "data = {\"accuracy\": results[\"mean_test_score\"]}\n",
        "for i, param in enumerate(results[\"params\"]):\n",
        "    for key, value in param.items():\n",
        "        if key not in data:\n",
        "            data[key] = [None] * len(results[\"params\"])\n",
        "        data[key][i] = value\n",
        "\n",
        "# Create DataFrame\n",
        "hp_df = pd.DataFrame(data).sort_values(by=\"accuracy\", ascending=False)\n",
        "hp_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_model = grid_search.to_sklearn().best_estimator_\n",
        "optimal_n_estimators = optimal_model.n_estimators\n",
        "optimal_learning_rate = optimal_model.learning_rate\n",
        "optimal_accuracy = hp_df[\"accuracy\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create function to add one to our model number if it already exists\n",
        "\n",
        "\n",
        "def model_version_update(df, name):\n",
        "    filtered_df = df.filter(col(\"NAME\") == name)\n",
        "    if filtered_df.count() == 0:\n",
        "        return 1\n",
        "    else:\n",
        "        filtered_df = filtered_df.withColumn(\n",
        "            \"VERSION\", filtered_df[\"VERSION\"].cast(\"int\")\n",
        "        )\n",
        "        max_version = filtered_df.agg({\"VERSION\": \"max\"}).collect()[0][0]\n",
        "        return max_version + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get sample input data to pass into the registry logging function\n",
        "X = train_df.drop(\"SURVIVED\").limit(100)\n",
        "\n",
        "db = identifier._get_unescaped_name(session.get_current_database())\n",
        "schema = identifier._get_unescaped_name(session.get_current_schema())\n",
        "\n",
        "# Define model name and version\n",
        "model_name = \"titanic\"\n",
        "\n",
        "# Create a registry and log the model\n",
        "registry = model_registry.ModelRegistry(\n",
        "    session=session, database_name=db, schema_name=schema, create_if_not_exists=True\n",
        ")\n",
        "\n",
        "reg_df = registry.list_models()\n",
        "model_version = model_version_update(reg_df, model_name)\n",
        "\n",
        "registry.log_model(\n",
        "    model_name=model_name,\n",
        "    model_version=model_version,\n",
        "    model=optimal_model,\n",
        "    sample_input_data=X,\n",
        "    options={\n",
        "        \"embed_local_ml_library\": True,  # This option is enabled to pull latest dev code changes.\n",
        "        \"relax\": True,\n",
        "    },  # relax dependencies\n",
        ")\n",
        "\n",
        "# Add evaluation metric\n",
        "registry.set_metric(\n",
        "    model_name=model_name,\n",
        "    model_version=model_version,\n",
        "    metric_name=\"accuracy\",\n",
        "    metric_value=optimal_accuracy,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's confirm it was added\n",
        "reg_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have multiple versions of the model, we want the UDF to be deployed as the version with the highest accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = (\n",
        "    reg_df.flatten(reg_df[\"METRICS\"])\n",
        "    .filter(col(\"KEY\") == \"accuracy\")\n",
        "    .select(\"name\", \"VERSION\", col(\"value\").as_(\"ACCURACY\"))\n",
        ")\n",
        "best_model.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the best model and version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployed_version = (\n",
        "    best_model.sort(col(\"ACCURACY\"), ascending=False).limit(1).collect()[0][1]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We can always get a reference to our registry and model using this function call\n",
        "model_ref = model_registry.ModelReference(\n",
        "    registry=registry, model_name=model_name, model_version=deployed_version\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_deployment_name = \"survival_pred\"\n",
        "\n",
        "model_ref.deploy(\n",
        "    deployment_name=\"survival_pred\",\n",
        "    target_method=\"predict\",  # the name of the model's method, usually predict\n",
        "    permanent=True,\n",
        "    options={\n",
        "        \"replace_udf\": \"True\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's confirm it was added\n",
        "registry.list_deployments(model_name, model_version).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We can then use the deployed model to perform inference\n",
        "result_sdf = model_ref.predict(deployment_name=\"survival_pred\", data=test_df)\n",
        "# result_sdf.rename(F.col('\"output_feature_0\"'),\"PREDICTED_PRICE\").show()\n",
        "result_sdf.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ref.predict(\"survival_pred\", test_df).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df.write.mode(\"overwrite\").save_as_table(\"TEST_DATA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_deployment_name = \"survival_pred_proba\"\n",
        "\n",
        "model_ref.deploy(\n",
        "    deployment_name=\"survival_pred_proba\",\n",
        "    target_method=\"predict_proba\",  # the name of the model's method, usually predict\n",
        "    permanent=True,\n",
        "    options={\n",
        "        \"replace_udf\": \"True\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ref.predict(\"survival_pred_proba\", test_df).drop(\"output_feature_0\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add images to stage for Streamlit App\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session.file.put(\"../streamlit_images/*\", \"@ML_DATA\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Intro_SnowML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
