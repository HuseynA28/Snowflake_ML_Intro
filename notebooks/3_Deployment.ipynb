{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "from snowflake.ml._internal.utils import identifier\n",
        "from snowflake.ml.modeling.impute import SimpleImputer\n",
        "from snowflake.ml.modeling.metrics import accuracy_score, precision_score, recall_score\n",
        "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
        "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
        "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
        "from snowflake.ml.registry import Registry\n",
        "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark import types as T\n",
        "from snowflake.snowpark.functions import col\n",
        "import ast\n",
        "import json\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session = Session.builder.configs(SnowflakeLoginOptions()).getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df = session.table(\"titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Columns with null values and their respective counts\n",
        "{\n",
        "    k: v\n",
        "    for k, v in {\n",
        "        col_name: titanic_df.where(col(col_name).is_null()).count()\n",
        "        for col_name in titanic_df.columns\n",
        "    }.items()\n",
        "    if v > 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df = titanic_df.drop(\n",
        "    [\"AGE\", \"DECK\", \"ALIVE\", \"ADULT_MALE\", \"EMBARKED\", \"SEX\", \"PCLASS\", \"ALONE\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_df = titanic_df.withColumn(\"FARE\", titanic_df[\"FARE\"].astype(T.FloatType()))\n",
        "\n",
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_cols = [\"CLASS\", \"WHO\", \"EMBARK_TOWN\"]\n",
        "num_cols = [\"SIBSP\", \"PARCH\", \"FARE\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "impute_cat = SimpleImputer(\n",
        "    input_cols=cat_cols,\n",
        "    output_cols=cat_cols,\n",
        "    strategy=\"most_frequent\",\n",
        "    drop_input_cols=True,\n",
        ")\n",
        "\n",
        "titanic_df = impute_cat.fit(titanic_df).transform(titanic_df)\n",
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OHE = OneHotEncoder(\n",
        "    input_cols=cat_cols,\n",
        "    output_cols=cat_cols,\n",
        "    drop_input_cols=True,\n",
        "    drop=\"first\",\n",
        "    handle_unknown=\"ignore\",\n",
        ")\n",
        "\n",
        "titanic_df = OHE.fit(titanic_df).transform(titanic_df)\n",
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = titanic_df.random_split(weights=[0.8, 0.2], seed=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
        "    \"learning_rate\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    \"max_depth\": list(range(3,6,1)),\n",
        "    \"min_child_weight\": list(range(1,6,1))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session.sql(\n",
        "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=LARGE;\"\n",
        ").collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data scientists may not have the ability to change the warehouse size.  They will usually have access to a larger warehouse and can easily switch as well using session.use_warehouse('bigger_warehouse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(\n",
        "    estimator=XGBClassifier(),\n",
        "    param_grid=parameters,\n",
        "    n_jobs=-1,\n",
        "    scoring=\"accuracy\",\n",
        "    input_cols=train_df.drop(\"SURVIVED\").columns,\n",
        "    label_cols=\"SURVIVED\",\n",
        "    output_cols=\"PRED_SURVIVED\",\n",
        ")\n",
        "\n",
        "# Train\n",
        "grid_search.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session.sql(\n",
        "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=XSMALL;\"\n",
        ").collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = grid_search.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(\n",
        "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print each combination of hyperparameters with their accuracy\n",
        "results = grid_search.to_sklearn().cv_results_\n",
        "data = {\"accuracy\": results[\"mean_test_score\"]}\n",
        "for i, param in enumerate(results[\"params\"]):\n",
        "    for key, value in param.items():\n",
        "        if key not in data:\n",
        "            data[key] = [None] * len(results[\"params\"])\n",
        "        data[key][i] = value\n",
        "\n",
        "# Create DataFrame\n",
        "hp_df = pd.DataFrame(data).sort_values(by=\"accuracy\", ascending=False)\n",
        "hp_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_model = grid_search.to_sklearn().best_estimator_\n",
        "optimal_n_estimators = optimal_model.n_estimators\n",
        "optimal_learning_rate = optimal_model.learning_rate\n",
        "optimal_max_depth = optimal_model.max_depth\n",
        "optimal_min_child_weight = optimal_model.min_child_weight\n",
        "optimal_accuracy = hp_df[\"accuracy\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create function to add one to our model versions if it already exists\n",
        "\n",
        "def check_and_update(df, model_name):\n",
        "    if df.empty:\n",
        "        return 'V_1'\n",
        "    elif df[df['name'] == model_name].empty:\n",
        "        return 'V_1'\n",
        "    else:\n",
        "        # Increment model_version if df is not a pandas Series\n",
        "        lst = sorted(ast.literal_eval(df['versions'][0]))\n",
        "        last_value = lst[-1] \n",
        "        prefix, num = last_value.rsplit('_', 1)\n",
        "        new_last_value = f\"{prefix}_{int(num)+1}\"\n",
        "        lst[-1] = new_last_value\n",
        "        return new_last_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get sample input data to pass into the registry logging function\n",
        "X = train_df.drop(\"SURVIVED\").limit(100)\n",
        "\n",
        "# Create a registry and log the model\n",
        "# You can specify a different DB and Schema if you'd like \n",
        "# otherwise it uses the sesion context\n",
        "reg = Registry(session=session)\n",
        "\n",
        "reg_df = reg.show_models()\n",
        "\n",
        "# Define model name and version (use uppercase for name)\n",
        "model_name = \"TITANIC\"\n",
        "\n",
        "model_version = check_and_update(reg_df, model_name)\n",
        "\n",
        "titanic_model = reg.log_model(\n",
        "    model_name=model_name,\n",
        "    version_name=model_version,\n",
        "    model=optimal_model,\n",
        "    sample_input_data=X,\n",
        ")\n",
        "\n",
        "# Add evaluation metric\n",
        "titanic_model.set_metric(\n",
        "    metric_name=\"accuracy\",\n",
        "    value=optimal_accuracy,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reg.show_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    \"optimal_n_estimators\" : optimal_n_estimators,\n",
        "    \"optimal_learning_rate\" : optimal_learning_rate,\n",
        "    \"optimal_max_depth\" : optimal_max_depth,\n",
        "    \"optimal_min_child_weight\" : optimal_min_child_weight\n",
        "}\n",
        "\n",
        "titanic_model.set_metric(metric_name=\"hyperparameters\", value=hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.options.display.max_colwidth = 500\n",
        "reg.get_model(model_name).show_versions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have multiple versions of the model, we want the UDF to be deployed as the version with the highest accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reg_df = reg.get_model(model_name).show_versions()\n",
        "reg_df[\"accuracy\"] = reg_df[\"metadata\"].apply(\n",
        "    lambda x: json.loads(x)[\"metrics\"][\"accuracy\"]\n",
        ")\n",
        "best_model = reg_df.sort_values(by=\"accuracy\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployed_version = best_model['name'].iloc[0]\n",
        "deployed_version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the default version to the deployed version (best model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = reg.get_model(model_name)\n",
        "m.default = deployed_version\n",
        "mv = m.default\n",
        "mv.version_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remote_prediction = mv.run(test_df, function_name=\"predict_proba\")\n",
        "remote_prediction.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To test in SQL write test data back to a table\n",
        "\n",
        "test_df.write.mode(\"overwrite\").save_as_table(\"TEST_DATA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add images to stage for Streamlit App\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session.file.put(\"../streamlit_images/*\", \"@ML_DATA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calling model from a new notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Point to the registry\n",
        "\n",
        "reg = Registry(session=session)\n",
        "\n",
        "# Get the default version of your model (Model with best accuracy in our case)\n",
        "\n",
        "mv = reg.get_model(\"titanic\").default\n",
        "\n",
        "remote_prediction = mv.run(test_df, function_name=\"predict_proba\")\n",
        "remote_prediction.drop('\"output_feature_0\"').with_column_renamed('\"output_feature_1\"','pred_survived').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## To delete your model and all of it's versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reg.delete_model(\"TITANIC\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Intro_SnowML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
