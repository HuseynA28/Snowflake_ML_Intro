{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PandasSeries' from 'snowflake.snowpark.types' (/opt/anaconda3/envs/Intro_SnowML/lib/python3.10/site-packages/snowflake/snowpark/types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/cromano/Desktop/DSBA5122_F23/Snowflake_ML_Intro/3_Deployment.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cromano/Desktop/DSBA5122_F23/Snowflake_ML_Intro/3_Deployment.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cromano/Desktop/DSBA5122_F23/Snowflake_ML_Intro/3_Deployment.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, precision_score, recall_score\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cromano/Desktop/DSBA5122_F23/Snowflake_ML_Intro/3_Deployment.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHotEncoder\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Intro_SnowML/lib/python3.10/site-packages/snowflake/ml/modeling/impute/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m pkg_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(\u001b[39m__file__\u001b[39m))\n\u001b[1;32m      6\u001b[0m pkg_name \u001b[39m=\u001b[39m \u001b[39m__name__\u001b[39m\n\u001b[0;32m----> 7\u001b[0m exportable_classes \u001b[39m=\u001b[39m init_utils\u001b[39m.\u001b[39;49mfetch_classes_from_modules_in_pkg_dir(pkg_dir\u001b[39m=\u001b[39;49mpkg_dir, pkg_name\u001b[39m=\u001b[39;49mpkg_name)\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m exportable_classes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      9\u001b[0m     \u001b[39mglobals\u001b[39m()[k] \u001b[39m=\u001b[39m v\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Intro_SnowML/lib/python3.10/site-packages/snowflake/ml/_internal/init_utils.py:26\u001b[0m, in \u001b[0;36mfetch_classes_from_modules_in_pkg_dir\u001b[0;34m(pkg_dir, pkg_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# import the module and iterate through its attributes\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mpkg_name\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodule_info\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m     \u001b[39mfor\u001b[39;00m attribute_name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(module):\n\u001b[1;32m     28\u001b[0m         attribute \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, attribute_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Intro_SnowML/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Intro_SnowML/lib/python3.10/site-packages/snowflake/ml/modeling/impute/iterative_imputer.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnowpark\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnowpark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtype_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_sp_to_sf_type\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnowpark_handlers\u001b[39;00m \u001b[39mimport\u001b[39;00m SnowparkHandlers \u001b[39mas\u001b[39;00m HandlersImpl\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     gather_dependencies,\n\u001b[1;32m     31\u001b[0m     original_estimator_has_callable,\n\u001b[1;32m     32\u001b[0m     transform_snowml_obj_to_sklearn_obj,\n\u001b[1;32m     33\u001b[0m     validate_sklearn_args,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnowpark_handlers\u001b[39;00m \u001b[39mimport\u001b[39;00m SklearnWrapperProvider\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Intro_SnowML/lib/python3.10/site-packages/snowflake/ml/modeling/_internal/snowpark_handlers.py:42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnowpark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m col, pandas_udf, sproc, udtf\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnowpark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstored_procedure\u001b[39;00m \u001b[39mimport\u001b[39;00m StoredProcedure\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msnowflake\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnowpark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     IntegerType,\n\u001b[1;32m     44\u001b[0m     PandasSeries,\n\u001b[1;32m     45\u001b[0m     StringType,\n\u001b[1;32m     46\u001b[0m     StructField,\n\u001b[1;32m     47\u001b[0m     StructType,\n\u001b[1;32m     48\u001b[0m     VariantType,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m cp\u001b[39m.\u001b[39mregister_pickle_by_value(inspect\u001b[39m.\u001b[39mgetmodule(get_temp_file_path))\n\u001b[1;32m     53\u001b[0m _PROJECT \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mModelDevelopment\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PandasSeries' from 'snowflake.snowpark.types' (/opt/anaconda3/envs/Intro_SnowML/lib/python3.10/site-packages/snowflake/snowpark/types.py)"
     ]
    }
   ],
   "source": [
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.metrics import accuracy_score, precision_score, recall_score\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session, types as T\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SnowflakeLoginOptions() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "session = Session.builder.configs(SnowflakeLoginOptions()).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = session.table(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SURVIVED\"  |\"PCLASS\"  |\"SEX\"   |\"AGE\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"   |\"EMBARKED\"  |\"CLASS\"  |\"WHO\"  |\"ADULT_MALE\"  |\"DECK\"  |\"EMBARK_TOWN\"  |\"ALIVE\"  |\"ALONE\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0           |3         |male    |22.00  |1        |0        |7.2500   |S           |Third    |man    |True          |NULL    |Southampton    |False    |False    |\n",
      "|1           |1         |female  |38.00  |1        |0        |71.2833  |C           |First    |woman  |False         |C       |Cherbourg      |True     |False    |\n",
      "|1           |3         |female  |26.00  |0        |0        |7.9250   |S           |Third    |woman  |False         |NULL    |Southampton    |True     |True     |\n",
      "|1           |1         |female  |35.00  |1        |0        |53.1000  |S           |First    |woman  |False         |C       |Southampton    |True     |False    |\n",
      "|0           |3         |male    |35.00  |0        |0        |8.0500   |S           |Third    |man    |True          |NULL    |Southampton    |False    |True     |\n",
      "|0           |3         |male    |NULL   |0        |0        |8.4583   |Q           |Third    |man    |True          |NULL    |Queenstown     |False    |True     |\n",
      "|0           |1         |male    |54.00  |0        |0        |51.8625  |S           |First    |man    |True          |E       |Southampton    |False    |True     |\n",
      "|0           |3         |male    |2.00   |3        |1        |21.0750  |S           |Third    |child  |False         |NULL    |Southampton    |False    |False    |\n",
      "|1           |3         |female  |27.00  |0        |2        |11.1333  |S           |Third    |woman  |False         |NULL    |Southampton    |True     |False    |\n",
      "|1           |2         |female  |14.00  |1        |0        |30.0708  |C           |Second   |child  |False         |NULL    |Cherbourg      |True     |False    |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SURVIVED', 0),\n",
       " ('PCLASS', 0),\n",
       " ('SEX', 0),\n",
       " ('AGE', 177),\n",
       " ('SIBSP', 0),\n",
       " ('PARCH', 0),\n",
       " ('FARE', 0),\n",
       " ('EMBARKED', 2),\n",
       " ('CLASS', 0),\n",
       " ('WHO', 0),\n",
       " ('ADULT_MALE', 0),\n",
       " ('DECK', 688),\n",
       " ('EMBARK_TOWN', 2),\n",
       " ('ALIVE', 0),\n",
       " ('ALONE', 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with null values and their respective counts\n",
    "null_counts = [\n",
    "    (col_name, titanic_df.where(col(col_name).isNull()).count())\n",
    "    for col_name in titanic_df.columns\n",
    "]\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop([\"AGE\", \"DECK\", \"ALIVE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SURVIVED\"  |\"PCLASS\"  |\"SEX\"   |\"SIBSP\"  |\"PARCH\"  |\"EMBARKED\"  |\"CLASS\"  |\"WHO\"  |\"ADULT_MALE\"  |\"EMBARK_TOWN\"  |\"ALONE\"  |\"FARE\"   |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0           |3         |male    |1        |0        |S           |Third    |man    |True          |Southampton    |False    |7.25     |\n",
      "|1           |1         |female  |1        |0        |C           |First    |woman  |False         |Cherbourg      |False    |71.2833  |\n",
      "|1           |3         |female  |0        |0        |S           |Third    |woman  |False         |Southampton    |True     |7.925    |\n",
      "|1           |1         |female  |1        |0        |S           |First    |woman  |False         |Southampton    |False    |53.1     |\n",
      "|0           |3         |male    |0        |0        |S           |Third    |man    |True          |Southampton    |True     |8.05     |\n",
      "|0           |3         |male    |0        |0        |Q           |Third    |man    |True          |Queenstown     |True     |8.4583   |\n",
      "|0           |1         |male    |0        |0        |S           |First    |man    |True          |Southampton    |True     |51.8625  |\n",
      "|0           |3         |male    |3        |1        |S           |Third    |child  |False         |Southampton    |False    |21.075   |\n",
      "|1           |3         |female  |0        |2        |S           |Third    |woman  |False         |Southampton    |False    |11.1333  |\n",
      "|1           |2         |female  |1        |0        |C           |Second   |child  |False         |Cherbourg      |False    |30.0708  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.withColumn(\"FARE\", titanic_df[\"FARE\"].astype(T.FloatType()))\n",
    "\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"SEX\", \"EMBARKED\", \"CLASS\", \"WHO\", \"EMBARK_TOWN\"]\n",
    "num_cols = [\"PCLASS\", \"SIBSP\", \"PARCH\", \"FARE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SEX\"   |\"EMBARKED\"  |\"CLASS\"  |\"WHO\"  |\"EMBARK_TOWN\"  |\"SURVIVED\"  |\"PCLASS\"  |\"SIBSP\"  |\"PARCH\"  |\"ADULT_MALE\"  |\"ALONE\"  |\"FARE\"   |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|male    |S           |Third    |man    |Southampton    |0           |3         |1        |0        |True          |False    |7.25     |\n",
      "|female  |C           |First    |woman  |Cherbourg      |1           |1         |1        |0        |False         |False    |71.2833  |\n",
      "|female  |S           |Third    |woman  |Southampton    |1           |3         |0        |0        |False         |True     |7.925    |\n",
      "|female  |S           |First    |woman  |Southampton    |1           |1         |1        |0        |False         |False    |53.1     |\n",
      "|male    |S           |Third    |man    |Southampton    |0           |3         |0        |0        |True          |True     |8.05     |\n",
      "|male    |Q           |Third    |man    |Queenstown     |0           |3         |0        |0        |True          |True     |8.4583   |\n",
      "|male    |S           |First    |man    |Southampton    |0           |1         |0        |0        |True          |True     |51.8625  |\n",
      "|male    |S           |Third    |child  |Southampton    |0           |3         |3        |1        |False         |False    |21.075   |\n",
      "|female  |S           |Third    |woman  |Southampton    |1           |3         |0        |2        |False         |False    |11.1333  |\n",
      "|female  |C           |Second   |child  |Cherbourg      |1           |2         |1        |0        |False         |False    |30.0708  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impute_cat = SimpleImputer(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    strategy=\"most_frequent\",\n",
    "    drop_input_cols=True,\n",
    ")\n",
    "\n",
    "titanic_df = impute_cat.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SEX_male\"  |\"EMBARKED_Q\"  |\"EMBARKED_S\"  |\"CLASS_Second\"  |\"CLASS_Third\"  |\"WHO_man\"  |\"WHO_woman\"  |\"EMBARK_TOWN_Queenstown\"  |\"EMBARK_TOWN_Southampton\"  |\"SURVIVED\"  |\"PCLASS\"  |\"SIBSP\"  |\"PARCH\"  |\"ADULT_MALE\"  |\"ALONE\"  |\"FARE\"   |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1.0         |0.0           |1.0           |0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |3         |1        |0        |True          |False    |7.25     |\n",
      "|0.0         |0.0           |0.0           |0.0             |0.0            |0.0        |1.0          |0.0                       |0.0                        |1           |1         |1        |0        |False         |False    |71.2833  |\n",
      "|0.0         |0.0           |1.0           |0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |3         |0        |0        |False         |True     |7.925    |\n",
      "|0.0         |0.0           |1.0           |0.0             |0.0            |0.0        |1.0          |0.0                       |1.0                        |1           |1         |1        |0        |False         |False    |53.1     |\n",
      "|1.0         |0.0           |1.0           |0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |3         |0        |0        |True          |True     |8.05     |\n",
      "|1.0         |1.0           |0.0           |0.0             |1.0            |1.0        |0.0          |1.0                       |0.0                        |0           |3         |0        |0        |True          |True     |8.4583   |\n",
      "|1.0         |0.0           |1.0           |0.0             |0.0            |1.0        |0.0          |0.0                       |1.0                        |0           |1         |0        |0        |True          |True     |51.8625  |\n",
      "|1.0         |0.0           |1.0           |0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3         |3        |1        |False         |False    |21.075   |\n",
      "|0.0         |0.0           |1.0           |0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |3         |0        |2        |False         |False    |11.1333  |\n",
      "|0.0         |0.0           |0.0           |1.0             |0.0            |0.0        |0.0          |0.0                       |0.0                        |1           |2         |1        |0        |False         |False    |30.0708  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OHE = OneHotEncoder(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    drop_input_cols=True,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "titanic_df = OHE.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = titanic_df.random_split(weights=[0.8, 0.2], seed=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.modeling.xgboost.xgb_classifier.XGBClassifier at 0x16a3ac190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    input_cols=train_df.drop(\"SURVIVED\").columns,\n",
    "    label_cols=\"SURVIVED\",\n",
    "    output_cols=\"PRED_SURVIVED\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = xgb.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn<1.4'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "DataFrame.flatten() is deprecated since 0.7.0. Use `DataFrame.join_table_function()` instead.\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn<1.4'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805714, Precision: 0.7636363636363637, Recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(\n",
    "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
    ")\n",
    "\n",
    "precision = precision_score(\n",
    "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
    ")\n",
    "\n",
    "recall = recall_score(\n",
    "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
