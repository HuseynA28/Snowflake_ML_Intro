{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.metrics import accuracy_score, precision_score, recall_score\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session, types as T\n",
    "from snowflake.snowpark.functions import col\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SnowflakeLoginOptions() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "session = Session.builder.configs(SnowflakeLoginOptions()).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = session.table(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SURVIVED\"  |\"PCLASS\"  |\"SEX\"   |\"AGE\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"   |\"EMBARKED\"  |\"CLASS\"  |\"WHO\"  |\"ADULT_MALE\"  |\"DECK\"  |\"EMBARK_TOWN\"  |\"ALIVE\"  |\"ALONE\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0           |3         |male    |22.00  |1        |0        |7.2500   |S           |Third    |man    |True          |NULL    |Southampton    |False    |False    |\n",
      "|1           |1         |female  |38.00  |1        |0        |71.2833  |C           |First    |woman  |False         |C       |Cherbourg      |True     |False    |\n",
      "|1           |3         |female  |26.00  |0        |0        |7.9250   |S           |Third    |woman  |False         |NULL    |Southampton    |True     |True     |\n",
      "|1           |1         |female  |35.00  |1        |0        |53.1000  |S           |First    |woman  |False         |C       |Southampton    |True     |False    |\n",
      "|0           |3         |male    |35.00  |0        |0        |8.0500   |S           |Third    |man    |True          |NULL    |Southampton    |False    |True     |\n",
      "|0           |3         |male    |NULL   |0        |0        |8.4583   |Q           |Third    |man    |True          |NULL    |Queenstown     |False    |True     |\n",
      "|0           |1         |male    |54.00  |0        |0        |51.8625  |S           |First    |man    |True          |E       |Southampton    |False    |True     |\n",
      "|0           |3         |male    |2.00   |3        |1        |21.0750  |S           |Third    |child  |False         |NULL    |Southampton    |False    |False    |\n",
      "|1           |3         |female  |27.00  |0        |2        |11.1333  |S           |Third    |woman  |False         |NULL    |Southampton    |True     |False    |\n",
      "|1           |2         |female  |14.00  |1        |0        |30.0708  |C           |Second   |child  |False         |NULL    |Cherbourg      |True     |False    |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SURVIVED', 0),\n",
       " ('PCLASS', 0),\n",
       " ('SEX', 0),\n",
       " ('AGE', 177),\n",
       " ('SIBSP', 0),\n",
       " ('PARCH', 0),\n",
       " ('FARE', 0),\n",
       " ('EMBARKED', 2),\n",
       " ('CLASS', 0),\n",
       " ('WHO', 0),\n",
       " ('ADULT_MALE', 0),\n",
       " ('DECK', 688),\n",
       " ('EMBARK_TOWN', 2),\n",
       " ('ALIVE', 0),\n",
       " ('ALONE', 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with null values and their respective counts\n",
    "null_counts = [\n",
    "    (col_name, titanic_df.where(col(col_name).isNull()).count())\n",
    "    for col_name in titanic_df.columns\n",
    "]\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop([\"AGE\", \"DECK\", \"ALIVE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SURVIVED\"  |\"PCLASS\"  |\"SEX\"   |\"SIBSP\"  |\"PARCH\"  |\"EMBARKED\"  |\"CLASS\"  |\"WHO\"  |\"ADULT_MALE\"  |\"EMBARK_TOWN\"  |\"ALONE\"  |\"FARE\"   |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0           |3         |male    |1        |0        |S           |Third    |man    |True          |Southampton    |False    |7.25     |\n",
      "|1           |1         |female  |1        |0        |C           |First    |woman  |False         |Cherbourg      |False    |71.2833  |\n",
      "|1           |3         |female  |0        |0        |S           |Third    |woman  |False         |Southampton    |True     |7.925    |\n",
      "|1           |1         |female  |1        |0        |S           |First    |woman  |False         |Southampton    |False    |53.1     |\n",
      "|0           |3         |male    |0        |0        |S           |Third    |man    |True          |Southampton    |True     |8.05     |\n",
      "|0           |3         |male    |0        |0        |Q           |Third    |man    |True          |Queenstown     |True     |8.4583   |\n",
      "|0           |1         |male    |0        |0        |S           |First    |man    |True          |Southampton    |True     |51.8625  |\n",
      "|0           |3         |male    |3        |1        |S           |Third    |child  |False         |Southampton    |False    |21.075   |\n",
      "|1           |3         |female  |0        |2        |S           |Third    |woman  |False         |Southampton    |False    |11.1333  |\n",
      "|1           |2         |female  |1        |0        |C           |Second   |child  |False         |Cherbourg      |False    |30.0708  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.withColumn(\"FARE\", titanic_df[\"FARE\"].astype(T.FloatType()))\n",
    "\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"SEX\", \"EMBARKED\", \"CLASS\", \"WHO\", \"EMBARK_TOWN\"]\n",
    "num_cols = [\"PCLASS\", \"SIBSP\", \"PARCH\", \"FARE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SEX\"   |\"EMBARKED\"  |\"CLASS\"  |\"WHO\"  |\"EMBARK_TOWN\"  |\"SURVIVED\"  |\"PCLASS\"  |\"SIBSP\"  |\"PARCH\"  |\"ADULT_MALE\"  |\"ALONE\"  |\"FARE\"   |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|male    |S           |Third    |man    |Southampton    |0           |3         |1        |0        |True          |False    |7.25     |\n",
      "|female  |C           |First    |woman  |Cherbourg      |1           |1         |1        |0        |False         |False    |71.2833  |\n",
      "|female  |S           |Third    |woman  |Southampton    |1           |3         |0        |0        |False         |True     |7.925    |\n",
      "|female  |S           |First    |woman  |Southampton    |1           |1         |1        |0        |False         |False    |53.1     |\n",
      "|male    |S           |Third    |man    |Southampton    |0           |3         |0        |0        |True          |True     |8.05     |\n",
      "|male    |Q           |Third    |man    |Queenstown     |0           |3         |0        |0        |True          |True     |8.4583   |\n",
      "|male    |S           |First    |man    |Southampton    |0           |1         |0        |0        |True          |True     |51.8625  |\n",
      "|male    |S           |Third    |child  |Southampton    |0           |3         |3        |1        |False         |False    |21.075   |\n",
      "|female  |S           |Third    |woman  |Southampton    |1           |3         |0        |2        |False         |False    |11.1333  |\n",
      "|female  |C           |Second   |child  |Cherbourg      |1           |2         |1        |0        |False         |False    |30.0708  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impute_cat = SimpleImputer(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    strategy=\"most_frequent\",\n",
    "    drop_input_cols=True,\n",
    ")\n",
    "\n",
    "titanic_df = impute_cat.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SEX_male\"  |\"EMBARKED_Q\"  |\"EMBARKED_S\"  |\"CLASS_Second\"  |\"CLASS_Third\"  |\"WHO_man\"  |\"WHO_woman\"  |\"EMBARK_TOWN_Queenstown\"  |\"EMBARK_TOWN_Southampton\"  |\"SURVIVED\"  |\"PCLASS\"  |\"SIBSP\"  |\"PARCH\"  |\"ADULT_MALE\"  |\"ALONE\"  |\"FARE\"   |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1.0         |0.0           |1.0           |0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |3         |1        |0        |True          |False    |7.25     |\n",
      "|0.0         |0.0           |0.0           |0.0             |0.0            |0.0        |1.0          |0.0                       |0.0                        |1           |1         |1        |0        |False         |False    |71.2833  |\n",
      "|0.0         |0.0           |1.0           |0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |3         |0        |0        |False         |True     |7.925    |\n",
      "|0.0         |0.0           |1.0           |0.0             |0.0            |0.0        |1.0          |0.0                       |1.0                        |1           |1         |1        |0        |False         |False    |53.1     |\n",
      "|1.0         |0.0           |1.0           |0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |3         |0        |0        |True          |True     |8.05     |\n",
      "|1.0         |1.0           |0.0           |0.0             |1.0            |1.0        |0.0          |1.0                       |0.0                        |0           |3         |0        |0        |True          |True     |8.4583   |\n",
      "|1.0         |0.0           |1.0           |0.0             |0.0            |1.0        |0.0          |0.0                       |1.0                        |0           |1         |0        |0        |True          |True     |51.8625  |\n",
      "|1.0         |0.0           |1.0           |0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3         |3        |1        |False         |False    |21.075   |\n",
      "|0.0         |0.0           |1.0           |0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |3         |0        |2        |False         |False    |11.1333  |\n",
      "|0.0         |0.0           |0.0           |1.0             |0.0            |0.0        |0.0          |0.0                       |0.0                        |1           |2         |1        |0        |False         |False    |30.0708  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OHE = OneHotEncoder(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    drop_input_cols=True,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "titanic_df = OHE.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = titanic_df.random_split(weights=[0.8, 0.2], seed=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\":[100, 200, 300, 400, 500],\n",
    "    \"learning_rate\":[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"ALTER WAREHOUSE COMPUTE_WH SET WAREHOUSE_SIZE=LARGE;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.modeling.model_selection.grid_search_cv.GridSearchCV at 0x7f91886032b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(),\n",
    "    param_grid=parameters,\n",
    "    n_jobs = -1,\n",
    "    scoring=\"accuracy\",\n",
    "    input_cols=train_df.drop(\"SURVIVED\").columns,\n",
    "    label_cols=\"SURVIVED\",\n",
    "    output_cols=\"PRED_SURVIVED\"\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"ALTER WAREHOUSE COMPUTE_WH SET WAREHOUSE_SIZE=XSMALL;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid_search.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.829787\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(\n",
    "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809341</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812209</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.807964</td>\n",
       "      <td>0.1</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.807964</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  learning_rate  n_estimators\n",
       "0  0.809341            0.1           100\n",
       "1  0.812209            0.1           200\n",
       "2  0.810811            0.1           300\n",
       "3  0.807964            0.1           400\n",
       "4  0.807964            0.1           500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print each combination of hyperparameters with their accuracy\n",
    "results = grid_search.to_sklearn().cv_results_\n",
    "data = {'Accuracy': results['mean_test_score']}\n",
    "for i, param in enumerate(results['params']):\n",
    "    for key, value in param.items():\n",
    "        if key not in data:\n",
    "            data[key] = [None] * len(results['params'])\n",
    "        data[key][i] = value\n",
    "\n",
    "# Create DataFrame\n",
    "hp_df = pd.DataFrame(data)\n",
    "hp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
